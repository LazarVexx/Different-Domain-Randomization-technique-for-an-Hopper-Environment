Results SAC without randomization:
source->source: Mean Reward = 303.74, Std Dev = 3.58
source->target: Mean Reward = 311.59, Std Dev = 4.35
target->target: Mean Reward = 325.37, Std Dev = 5.37

Results PPO without randomization:
source->source: Mean Reward = 540.08, Std Dev = 4.94
source->target: Mean Reward = 559.57, Std Dev = 7.85
target->target: Mean Reward = 1139.97, Std Dev = 26.95

Results SAC Uniform:


Results PPO Uniform:
source->source: Mean Reward = 1003.62, Std Dev = 49.50
source->target: Mean Reward = 1267.78, Std Dev = 15.83
target->target: Mean Reward = 332.64, Std Dev = 2.34

Results SAC Adaptive:


Results PPO Adaptive:
source->source: Mean Reward = 981.17, Std Dev = 10.16
source->target: Mean Reward = 993.18, Std Dev = 16.10
target->target: Mean Reward = 769.75, Std Dev = 4.07

Results SAC Continual:


Results PPO Continual:

source->source: Mean Reward = 582.12, Std Dev = 88.99
source->target: Mean Reward = 739.34, Std Dev = 172.01
target->target: Mean Reward = 1308.31, Std Dev = 29.67


Results SAC Entropy Regulation:



Results PPO Entropy Regulation:
source->source: Mean Reward = 594.14, Std Dev = 4.82
source->target: Mean Reward = 632.01, Std Dev = 2.78
target->target: Mean Reward = 854.05, Std Dev = 5.55